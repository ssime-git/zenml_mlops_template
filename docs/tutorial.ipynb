{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZenML MLOps Template - Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the ZenML MLOps template with all available make commands.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Docker and Docker Compose installed\n",
    "- Make installed\n",
    "- Run this notebook from the project root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. View Available Commands\n",
    "\n",
    "First, let's see all available make commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start All Services\n",
    "\n",
    "Start the infrastructure (ZenML, MLflow, MySQL, Inference API, Prometheus, Grafana):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for services to be ready (especially MySQL and ZenML):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"Waiting 60 seconds for services to initialize...\")\n",
    "time.sleep(60)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all services are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker compose ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Training Pipeline\n",
    "\n",
    "Run the ML training pipeline. On first run, this will:\n",
    "1. Activate the ZenML server (create admin user)\n",
    "2. Create a service account for authentication\n",
    "3. Generate an API key\n",
    "4. Execute the preprocessing and training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check API Health\n",
    "\n",
    "Verify the inference API is running and has loaded the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make a Prediction\n",
    "\n",
    "Send a prediction request to the inference API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make predictions programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Sample Iris flower measurements\n",
    "data = {\n",
    "    \"sepal_length\": 5.1,\n",
    "    \"sepal_width\": 3.5,\n",
    "    \"petal_length\": 1.4,\n",
    "    \"petal_width\": 0.2\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8000/predict\",\n",
    "    json=data\n",
    ")\n",
    "\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(f\"Response: {json.dumps(response.json(), indent=2)}\")\n",
    "\n",
    "# Map prediction to class name\n",
    "classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "prediction = response.json().get(\"prediction\", 0)\n",
    "print(f\"\\nPredicted class: {classes[prediction]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trigger Model Retraining\n",
    "\n",
    "Trigger a model retraining via the API endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Service Logs\n",
    "\n",
    "View logs from all services (press Ctrl+C to stop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View last 20 lines of logs from each service\n",
    "!docker compose logs --tail=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Access the Dashboards\n",
    "\n",
    "The following dashboards are available:\n",
    "\n",
    "| Service | URL | Credentials |\n",
    "|---------|-----|-------------|\n",
    "| ZenML Dashboard | http://localhost:8888 | admin / zenml |\n",
    "| MLflow UI | http://localhost:5001 | - |\n",
    "| Inference API Docs | http://localhost:8000/docs | - |\n",
    "| Prometheus | http://localhost:9092 | - |\n",
    "| Grafana | http://localhost:3002 | admin / admin |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dashboards in browser (uncomment to use)\n",
    "# import webbrowser\n",
    "# webbrowser.open(\"http://localhost:8888\")  # ZenML\n",
    "# webbrowser.open(\"http://localhost:5001\")  # MLflow\n",
    "# webbrowser.open(\"http://localhost:8000/docs\")  # API Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check Prometheus Metrics\n",
    "\n",
    "View the metrics exposed by the inference API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s http://localhost:8000/metrics | head -30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Build Docker Images\n",
    "\n",
    "Rebuild all Docker images (useful after code changes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Stop All Services\n",
    "\n",
    "Stop all running containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Full Cleanup\n",
    "\n",
    "Remove all containers, volumes, and data (for a fresh start):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This will delete all data!\n",
    "# Uncomment to run:\n",
    "# !make clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Command | Description |\n",
    "|---------|-------------|\n",
    "| `make help` | Show all available commands |\n",
    "| `make up` | Start all services |\n",
    "| `make down` | Stop all services |\n",
    "| `make build` | Build Docker images |\n",
    "| `make logs` | View service logs |\n",
    "| `make train` | Run training pipeline |\n",
    "| `make retrain` | Trigger retraining via API |\n",
    "| `make predict` | Make example prediction |\n",
    "| `make health` | Check API health |\n",
    "| `make clean` | Remove all data |\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐\n",
    "│  Pipeline       │────▶│  ZenML Server   │────▶│     MySQL       │\n",
    "│  Runner         │     │  (Port 8888)    │     │  (Port 3306)    │\n",
    "└─────────────────┘     └─────────────────┘     └─────────────────┘\n",
    "        │\n",
    "        ▼\n",
    "┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐\n",
    "│     MLflow      │◀────│  Inference API  │────▶│   Prometheus    │\n",
    "│  (Port 5001)    │     │  (Port 8000)    │     │  (Port 9092)    │\n",
    "└─────────────────┘     └─────────────────┘     └─────────────────┘\n",
    "                                                        │\n",
    "                                                        ▼\n",
    "                                                ┌─────────────────┐\n",
    "                                                │    Grafana      │\n",
    "                                                │  (Port 3002)    │\n",
    "                                                └─────────────────┘\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
