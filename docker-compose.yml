services:
  mysql:
    image: mysql:8.0.40
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: zenml
    volumes:
      - ./data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5

  zenml:
    image: zenmldocker/zenml-server:latest
    platform: linux/amd64
    ports:
      - "8888:8080"
    environment:
      ZENML_STORE_URL: mysql://root:password@mysql/zenml
      ZENML_DEFAULT_USER_NAME: admin
      ZENML_DEFAULT_USER_PASSWORD: ${ZENML_PASSWORD:-zenml}
      ZENML_DEFAULT_USER_EMAIL: admin@zenml.io
      ZENML_AUTH_TYPE: default
      ZENML_STORE_TYPE: sql
    depends_on:
      mysql:
        condition: service_healthy

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.18.0
    ports:
      - "5001:5000"
    volumes:
      - mlflow_data:/mlruns
    command: >
      mlflow server 
      --host 0.0.0.0
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/')"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ZenML pipeline runner - executes the full pipeline through ZenML orchestration
  # Run with: docker compose --profile pipeline run --rm pipeline-runner
  # 
  # The pipeline-runner automatically creates a service account and API key
  # using the admin credentials on first run.
  pipeline-runner:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.pipeline-runner
    volumes:
      - ./data-file:/app/data-file
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      ZENML_STORE_URL: http://zenml:8080
      # Admin credentials for auto-creating service account (must match zenml service)
      ZENML_DEFAULT_USER_NAME: admin
      ZENML_DEFAULT_USER_PASSWORD: ${ZENML_PASSWORD:-zenml}
    depends_on:
      - zenml
      - mlflow
    profiles:
      - pipeline  # Only run when explicitly requested

  inference-api:
    build:
      context: .
      dockerfile: dockerfiles/Dockerfile.inference
    volumes:
      - ./data-file:/app/data-file
      - mlflow_data:/mlruns:ro  # Read-only access to MLflow artifacts
      - /var/run/docker.sock:/var/run/docker.sock  # Docker socket for triggering pipeline
      - .:/app/workspace:ro  # Project files for docker compose
    ports:
      - "8000:8000"
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
    depends_on:
      mlflow:
        condition: service_healthy
    restart: on-failure
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  prometheus:
    image: prom/prometheus:v2.55.1
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9092:9090"
    depends_on:
      - inference-api

  grafana:
    image: grafana/grafana-oss:11.3.1
    ports:
      - "3002:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
      - ./config/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus

volumes:
  mlflow_data:
  mysql_data:
  prometheus_data:
  grafana_data: